## Author: Odey John Ebinyi
## Date: Wednesday, 24th August, 2022
## Twitter: @i_am_giannis
## Description: RXGBoost classifier for Malware & threat analysis using machine
## learning.

import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve

def plot_roc_curve(svm_clf, x_test, y_test):
    y_pred = svm_clf.predict(x_test)
    
    # roc_curves() returns a tuple for fpr(false positive rate), tpr(true positive rate),
    # and thresholds.
    fpr, tpr, thresholds = roc_curve(y_test, y_pred)
    
    plt.figure(figsize=(6, 4))
    plt.plot(fpr, tpr, linewidth=2)
    plt.plot([0,1], [0,1], 'k--')
    plt.axis([0, 1, 0, 1])
    plt.title('ROC Curve for XGBoost')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.show()
    
def conf_matrix(xgb_clf, x_test, y_test):
    y_pred = xgb_clf.predict(x_test)
    
    # annot=True adds numeric values in the heatmap cells. fmt="d" makes heatmap to use decimals when 
    # adding annotations. cmap is the color map which is set to blue. Color bar, cbar, is set to True.
    cf_matrix = sb.heatmap(confusion_matrix(y_pred, y_test), annot = True, fmt="d", cmap='YlGnBu', cbar=True)
    cf_matrix.set_title("Confusion Matrix for XGBoost")
    cf_matrix.set_xlabel('Predicted Values')
    cf_matrix.set_ylabel('Actual Values')
    
    cf_matrix.xaxis.set_ticklabels(['False', 'True'])
    cf_matrix.yaxis.set_ticklabels(['False', 'True'])
    plt.show()
    
def scale_feature(x_train, x_test):
    standard_scaler = StandardScaler()
    x_train = standard_scaler.fit_transform(x_train) # Fit x_train to data and then transform it
    x_test = standard_scaler.transform(x_test) # transform x_test.

def xgb_classification_report(xgb_clf, x_test, y_test):
    y_pred = xgb_clf.predict(x_test)
    print("*******************Classification Report**********************")
    print(classification_report(y_test, y_pred))
    
def xgb(train_data_frame):
    # Variable X is given dataset free from malware, while
    # variable y is given dataset with malware.
    X = train_data_frame.drop(['Name', 'Malware'], axis=1)
    y = train_data_frame['Malware']
    
    # dataset is split into 70% for training and 30% for testing i.e 0.3
    # random_state is set to 100 for the shuffling process. It determines how the data set is
    # split into training and testing.
    # X_train and X_test are independent variables.
    # X_train & y_train are 70% of the dataset and X_test & y_test are 30% of the dataset. y_train is a dependent variable
    # that depends on X_train, while y_test is also a dependent variable that depends on X_test.
    # The values of y_train must be equal to X_train. Also, the value of y_test must be equal to X_test.
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100)
    
    # feature scaling. 
    # This is essential for machine learning algorithms that calculate distances between
    # data. Scaling makes it easy for a model to learn and understand the problem.
    scale_feature(X_train, X_test)

    # max_depth: Maximum depth of the XGBoost classifier. This is the max depth of 
    #           the decision trees used by XGBoost.
    # learning rate: The rate at which XGBoost will learn during the training phase.
    #                It determines how fast XGBoost will learn.
    # n_estimators: Total number of estimators to be added during training. This is
    #               the total number of decision trees, which is 20.
    xgb_clf = XGBClassifier(max_depth=20, learning_rate=0.3, n_estimators=150, use_label_encoder=False)
    xgb_clf.fit(X_train, y_train)
    print("XGBoost Prediction: {0:.2f}%\n".format(xgb_clf.score(X_test, y_test) * 100))
    plot_roc_curve(xgb_clf, X_test, y_test)
    xgb_classification_report(xgb_clf, X_test, y_test)
    conf_matrix(xgb_clf, X_test, y_test)
    
if __name__ == '__main__':
    # First two lines reads in the dataset into train_data_frame and test_data_frame. 
    train_data_frame = pd.read_csv('dataset_malwares.csv', sep=',')
    test_data_frame = pd.read_csv('dataset_test.csv', sep=',')
    
    # call the xgb function to train xgb classifier.
    xgb(train_data_frame)